# 线性网络

## 线性回归

### 数学建模

线性回归常见用在一些简单问题上（例如房价预测）

线性假设是指目标（房屋价格）可以表示为特征（面积和房龄）的加权和，如下面的式子：

$$
\mathrm{price} = w_{\mathrm{area}} \cdot \mathrm{area} + w_{\mathrm{age}} \cdot \mathrm{age} + b.
$$
将式子总结一下可以写成线性代数结合权重的形式
$$
\hat{y} = w_1  x_1 + ... + w_d  x_d + b
$$
对于预测值（上方有尖括号）通过矩阵总结可以写成 
$$
{\hat{\mathbf{y}}} = \mathbf{X} \mathbf{w} + b
$$

随后就可以设置损失函数为平方误差

$$
l^{(i)}(\mathbf{w}, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2.
$$
在多个样本上求平均值，可以列出

$$
L(\mathbf{w}, b) =\frac{1}{n}\sum_{i=1}^n l^{(i)}(\mathbf{w}, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)^2.
$$

### 解析解

在训练模型的时候我们希望寻找一组参数，这组参数能最小化在所有训练样本上的总损失。如下式：

$$
\mathbf{w}^*, b^* = \operatorname*{argmin}_{\mathbf{w}, b}\  L(\mathbf{w}, b).
$$
通过数学推导我们其实是可以通过数学方式得到解析解的

$$
\mathbf{w}^* = (\mathbf X^\top \mathbf X)^{-1}\mathbf X^\top \mathbf{y}.
$$
但是在机器学习中日后的问题都没有这么简单，问题也不一定会有解析解
